# Databricks notebook source
# MAGIC %md
# MAGIC # 1. Ajuste del rendimiento de Apache Spark con Z-ORDERS‚ú®

# COMMAND ----------

# MAGIC %md
# MAGIC - Al consultar terabytes o petabytes de big data para an√°lisis con Apache Spark, es fundamental tener velocidades de consulta optimizadas. 
# MAGIC - Hay algunos comandos de optimizaci√≥n disponibles dentro de Databricks que se pueden usar para acelerar las consultas y hacerlas m√°s eficientes. 
# MAGIC -  Al ver que Z-ORDERS y la omisi√≥n de datos son caracter√≠sticas de optimizaci√≥n que est√°n disponibles en Databricks, 
# MAGIC 
# MAGIC  `¬øC√≥mo podemos comenzar a probarlas y usarlas en Databricks Notebooks?`

# COMMAND ----------

# MAGIC %md
# MAGIC <div style="text-align: center; line-height: 0; padding-top: 9px;">
# MAGIC   <img src="https://cms.databricks.com/sites/default/files/inline-images/optimize_where.jpg" alt="Z-ORDERS" style="width: 600px">
# MAGIC </div>

# COMMAND ----------

# MAGIC %md
# MAGIC Mas informaci√≥n: https://www.databricks.com/blog/2018/07/31/processing-petabytes-of-data-in-seconds-with-databricks-delta.html

# COMMAND ----------

# MAGIC %md
# MAGIC <img src="https://www.databricks.com/wp-content/uploads/2018/07/Screen-Shot-2018-07-30-at-2.03.55-PM.png" alt="Z-ORDERS">

# COMMAND ----------

# MAGIC %md
# MAGIC - El comando `OPTIMIZE` puede lograr esta compactaci√≥n por s√≠ solo sin Z-Ordering, sin embargo, `Z-Ordering` nos permite especificar la columna para compactar y optimizar, lo que afectar√° las velocidades de consulta si la columna especificada est√° en una cl√°usula Where y tiene una alta cardinalidad. 
# MAGIC - Adem√°s, la omisi√≥n de datos es una caracter√≠stica autom√°tica del comando de optimizaci√≥n y funciona bien cuando se combina con Z-Ordering.

# COMMAND ----------

flights = spark.read.format("csv")   \
        .option("header", "true")  \
        .option("inferSchema", "true")   \
        .load("/databricks-datasets/asa/airlines/2008.csv")


# COMMAND ----------

display(flights)

# COMMAND ----------

flights.count()

# COMMAND ----------

# Comprobamos en databricks las unidades montadas:
display(dbutils.fs.mounts())

# COMMAND ----------

# MAGIC %md
# MAGIC Guardamos el Spark Dataframe en formato delta y lo particionamos por columna origen

# COMMAND ----------

(
  flights
  .write
  .partitionBy("Origin")
  .format("delta")
  .mode("overwrite")
  .save("/mnt/demo/flights/flights_delta")
)

# COMMAND ----------

# MAGIC %md
# MAGIC - Una vez que el comando termina de ejecutarse, podemos ver en la imagen a continuaci√≥n que los datos de vuelo se han particionado y persistido en ADLS gen2. **Hay m√°s de 300 carpetas particionadas por 'Origen'.**
# MAGIC - Al navegar a delta_log, podemos ver los archivos de registro iniciales, representados principalmente por los archivos *.json.
# MAGIC - Despu√©s de descargar el archivo json delta_log inicial y abrirlo, podemos ver que se agregaron m√°s de 2310 archivos nuevos a las m√°s de 300 carpetas.

# COMMAND ----------

# MAGIC %md
# MAGIC # Ahora creamos una tabla delta con los ficheros que hemos persisitido en el DataLake

# COMMAND ----------

spark.sql("CREATE TABLE flights USING DELTA LOCATION '/mnt/demo/flights/flights_delta'")


# COMMAND ----------

# MAGIC %md
# MAGIC - Despu√©s de crear la tabla de Hive,verificamos el n√∫mero total de registros.
# MAGIC - Como podemos ver, este es un conjunto de datos bastante grande con **m√°s de 7 millones de registros.**

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT Count(*) FROM flights

# COMMAND ----------

# MAGIC %md
# MAGIC - A continuaci√≥n, podemos ejecutar una consulta m√°s compleja que aplicar√° un filtro a la tabla de vuelos en una columna sin particiones, D√≠a del mes. 
# MAGIC - En la visualizaci√≥n de resultados en la imagen a continuaci√≥n, podemos ver que la consulta tard√≥ m√°s de 2 minutos en completarse. 
# MAGIC - Este tiempo nos permite establecer el punto de referencia inicial para el tiempo de comparaci√≥n despu√©s de ejecutar el comando Z-Order.

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT count(*) as Flights, Dest, Month 
# MAGIC FROM flights 
# MAGIC WHERE DayofMonth = 5 
# MAGIC GROUP BY Month, Dest

# COMMAND ----------

# MAGIC %md
# MAGIC - A continuaci√≥n, podemos ejecutar el siguiente comando `OPTIMIZE` combinado con el comando `Z-ORDER` en la columna que queremos filtrar, que es `DayofMonth`. 
# MAGIC - Tenga en cuenta que las optimizaciones de orden Z funcionan mejor en columnas que tienen una **alta cardinalidad.**
# MAGIC - Seg√∫n los resultados, se eliminaron 2308 archivos y se agregaron 300 archivos como parte del proceso Z-ORDER OPTIMIZE.

# COMMAND ----------

# MAGIC %sql
# MAGIC OPTIMIZE flights ZORDER BY (DayofMonth)

# COMMAND ----------

# MAGIC %md
# MAGIC Dentro del **delta_log**, ahora hay un nuevo archivo json que podemos descargar y abrir para revisar los resultados.

# COMMAND ----------

# MAGIC %md
# MAGIC Como era de esperar, podemos ver las acciones realizadas en estos registros en funci√≥n de las l√≠neas de eliminaci√≥n y adici√≥n en el archivo json.

# COMMAND ----------

# MAGIC %md
# MAGIC - Como informaci√≥n adicional, al navegar dentro de una de las carpetas de partici√≥n, se ha creado un nuevo archivo. 
# MAGIC - Si bien el comando Orden Z puede personalizar el tama√±o de compactaci√≥n, generalmente apunta a alrededor de 1 GB por archivo cuando es posible.

# COMMAND ----------

# MAGIC %md
# MAGIC # Ahora ejecutamos de nuevo la misma consulta y vemos lo que tarda:

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT count(*) as Flights, Dest, Month 
# MAGIC FROM flights 
# MAGIC WHERE DayofMonth = 5 
# MAGIC GROUP BY Month, Dest

# COMMAND ----------

# MAGIC %md
# MAGIC ## Comprobamos que tarda unos `8.72 segundos` con respecto a los `41.56 segundos` de la primera ejecuci√≥n sin Z-ORDERS

# COMMAND ----------

# MAGIC %md
# MAGIC # 2. Data Skippingüß®

# COMMAND ----------

Data = "/databricks-datasets/nyctaxi/tripdata/yellow/yellow_tripdata_2019-*"

SchemaDF = spark.read.format("csv")   \
            .option("header", "true")  \
            .option("inferSchema", "true") \
            .load("/databricks-datasets/nyctaxi/tripdata/yellow/yellow_tripdata_2019-02.csv.gz")



# COMMAND ----------

# MAGIC %md
# MAGIC Creamos el Spark Dataframe

# COMMAND ----------

nyctaxiDF = spark.read.format("csv")\
.option("header", "true")\
.schema(SchemaDF.schema)\
.load(Data)

# COMMAND ----------

nyctaxiDF.display()

# COMMAND ----------

# MAGIC %md
# MAGIC - Este  bloque de c√≥digo agregar√° algunos campos de partici√≥n al Spark Dataframe existente por A√±o, A√±o_Mes y A√±o_Mes_D√≠a. 
# MAGIC - Estas columnas adicionales se basar√°n en la marca de fecha y hora y ayudar√°n con la partici√≥n, la omisi√≥n de datos, el Z-ORDER y, en √∫ltima instancia, velocidades de consulta m√°s eficaces.

# COMMAND ----------

from pyspark.sql.functions import *
nyctaxiDF = nyctaxiDF.withColumn('Year', year(col("tpep_pickup_datetime")))
nyctaxiDF = nyctaxiDF.withColumn('Year_Month', date_format(col("tpep_pickup_datetime"),"yyyyMM"))
nyctaxiDF = nyctaxiDF.withColumn('Year_Month_Day', date_format(col("tpep_pickup_datetime"),"yyyyMMdd"))

# COMMAND ----------

display(nyctaxiDF)

# COMMAND ----------

# MAGIC %md
# MAGIC Guardamos el Spark Dataframe en formato delta y lo particionamos por columna origen

# COMMAND ----------

(
nyctaxiDF
 .write
 .partitionBy("Year")
 .format("delta")
 .mode("overwrite")
 .save("/mnt/demo/nyctaxi/nyctaxi_delta")
)

# COMMAND ----------

# MAGIC %md
# MAGIC Como podemos ver en el archivo json delta_log, se agregaron ~400 archivos nuevos.

# COMMAND ----------

# MAGIC %md
# MAGIC A continuaci√≥n, podemos crear una tabla de Hive utilizando la ruta delta de ADLS2.

# COMMAND ----------

spark.sql("CREATE TABLE nyctaxi USING DELTA LOCATION '/mnt/demo/nyctaxi/nyctaxi_delta'")


# COMMAND ----------

# MAGIC %md
# MAGIC Podemos ver que la tabla Delta tiene mas de 84 millones de registros

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT count(*) FROM nyctaxi

# COMMAND ----------

# MAGIC %md
# MAGIC ## Ahora es el momento de aplicar Z-Ordering a la tabla en Year_Month_Day ejecutando el siguiente c√≥digo SQL.

# COMMAND ----------

# MAGIC %sql
# MAGIC OPTIMIZE nyctaxi 
# MAGIC ZORDER BY (Year_Month_Day)

# COMMAND ----------

# MAGIC %md
# MAGIC Como podemos ver en la imagen a continuaci√≥n, se eliminaron los 400 archivos y solo se agregaron 10 archivos nuevos. Adem√°s, tenga en cuenta que se trata de una eliminaci√≥n y adici√≥n l√≥gica. Para la eliminaci√≥n f√≠sica de archivos, ser√° necesario ejecutar el comando VACCUM .

# COMMAND ----------

# MAGIC %md
# MAGIC Para confirmar que solo se leen 10 archivos en una consulta, ejecutemos la siguiente consulta y luego verifiquemos el plan de consulta.

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT Year_Month_Day, count(*) 
# MAGIC FROM nyctaxi 
# MAGIC GROUP BY Year_Month_Day

# COMMAND ----------

# MAGIC %md
# MAGIC Dado que no se aplican condiciones  `where` a esta consulta, el plan de consulta SQL indica que se leyeron 10 archivos, como se esperaba.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Ahora podemos agregar una cl√°usula where en la columna que se optimiz√≥ Z-ORDER.

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT Year_Month_Day, count(*) 
# MAGIC FROM nyctaxi 
# MAGIC WHERE Year_Month_Day = '20191219' 
# MAGIC GROUP BY Year_Month_Day

# COMMAND ----------

# MAGIC %md
# MAGIC # 3. RESUMEN

# COMMAND ----------

# MAGIC %md
# MAGIC - Es importante tener en cuenta que `Z-Ordering` se puede aplicar a varias columnas, sin embargo, se recomienda tener cuidado con este enfoque, ya que agregar demasiadas columnas de Z-Order generar√° un costo. 
# MAGIC - Tambi√©n hay una funci√≥n de OPTIMIZACI√ìN AUTOM√ÅTICA que se puede aplicar; sin embargo, la funci√≥n OPTIMIZACI√ìN AUTOM√ÅTICA no aplicar√° el orden Z ya que deber√° hacerse manualmente. 
# MAGIC - Dada la cantidad significativa de tiempo que lleva ejecutar el comando Z-Order la primera vez, se recomienda considerar ejecutar `Z-ordering` con moderaci√≥n y como parte de una estrategia de mantenimiento (es decir, semanalmente, etc.). 
# MAGIC - Adem√°s, es importante tener en cuenta que Optimize y `Z-Ordering` se pueden ejecutar durante el horario comercial normal y no es necesario que se ejecuten solo como una tarea fuera de l√≠nea.
# MAGIC - El orden Z se puede aplicar de forma incremental a particiones y consultas despu√©s de la ejecuci√≥n inicial,

# COMMAND ----------


